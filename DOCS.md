# Docs

The app uses TypeScript, webpack 5, React and amCharts 5.

TO-DO: expand docs

## Building and Testing

The following npm scripts are available:

* `build`: build `app/` and `report/` using webpack and writes it to `dist/`
* `dev`: open a development server of `app/` and `report/` using webpack-serve
* `test`: run pipeline tests in `tests/`
* `format`: format code

## Developing

Run `npm run dev` and head to [http://localhost:8080](http://localhost:8080), generate a report, and you will see a green button that is not present in production "Download DATA". You should place the downloaded file in `assets/public` with the name `report_sample.data`.
Now you can head to [http://localhost:8080/report.html](http://localhost:8080/report.html) to debug the report UI.

## Demo generation

The [demo](https://chatanalytics.app/demo) is an export from the [DefleMask](https://www.deflemask.com) server which is from a friend of mine who gave me permission to use it as a demo. The input files are stored in a Google Drive zip and later downloaded during CI to build the demo HTML automatically using the CLI (with `--demo`). It is updated manually by me using:

```sh
docker run --rm -it -v $PWD/out:/out tyrrrz/discordchatexporter:stable exportguild -f json -g 253601524398293010 -t <token>
```

Zipping and then replacing the file in Google Drive (~280MB uncompressed, 23MB compressed).

---

## Pipeline

The raw platform files are read by specific parsers into a common format. After that, the final report data is generated by [DatabaseBuilder.ts](pipeline/process/DatabaseBuilder.ts). Then the database object is read by the report UI which aggregates the data to display the graphs and stats.

TO-DO: expand this

---

## Writing a new parser

### Parser class

You should implement a class that extends `Parser` and implements `parse(file)`, which parses a file at a time. You can check existing implementations to guide you.  

Basic template:
```typescript
import { Parser } from "@pipeline/parse/Parser";
import { FileInput } from "@pipeline/File";

export class MyPlatformParser extends Parser {

    async *parse(file: FileInput) {
        // parse here
    }

}
```

#### JSON-based parser

If your platform exports chats in JSON format and expect multiple GBs, you should stream the JSON object.

```typescript
import { JSONStream } from "@pipeline/parse/JSONStream";
import { streamJSONFromFile } from "@pipeline/File";
```

And then in your `parse(file)` function you can stream keys in the root like the following:

```typescript
const stream = new JSONStream();

stream.onObject<MyObject>("info", this.parseInfo.bind(this));
stream.onArrayItem<MyMessageItem>("messages", this.parseMessage.bind(this));

yield* streamJSONFromFile(stream, file);
```


#### Text/binary parsers

You can get the raw file bytes using `.slice()`. Then you can use TextEncoder to decode the UTF-8 sequence.

```typescript
const fileBuffer: Uint8Array = await file.slice();
const fileContent: string = new TextDecoder("utf-8").decode(fileBuffer);
```

### Platform specific changes

You will have to register this new platform in multiple places, start adding the relevant platform name to the `type Platform` in [Types.ts](pipeline/Types.ts). After that, if you try to compile you will get lots of errors of missing keys, you should complete everything (correctly). And probably in some other places I don't remember right now. You'll figure it out.

